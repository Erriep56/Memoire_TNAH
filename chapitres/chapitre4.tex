Dans l’« Artificial Intelligence Planning Framework » (Cadre de planification pour l’intelligence artificielle) proposé par le LC Labs de la Bibliothèque du Congrès en 2023\footnote{\cite{libraryofcongressPlanningFrameworkUsed2025}. Nous utilisons la traduction de Jean-Philippe Moreux : \cite{libraryofcongressPlanificationProjetIA2025}.}, proposant un guide pour les projets menés par les les institutions patrimoniales utilisant ces technologies, trois phases de planification sont mis en avant : Comprendre, expérimenter et mettre en œuvre, chacune soutenant l'évaluation de trois éléments nécessaires au projets : les données, les modèles et les personnes. La première phase consiste à comprendre le besoin et l’objectif de la tâche ainsi que le personnel mis en œuvre et les données qui seront utilisées pour la tâche. 

Dans le cas du projet d’indexation du RETIF accompagnée par l’intelligence artificielle, le but de l’expérimentation est de tester son automatisation pour fournir une indexation grâce au thésaurus Garnier sur la plateforme AGORHA. Si au sein du consortium PictorIA et de l’INHA, à l’initiative du projet, des personnels avec des compétences pouvaient fournir une assistance ponctuelle, une seule personne se consacrait à mener le projet sur une période courte de quatre mois. Les données à prendre en compte sont le corpus d’images du RETIF et les métadonnées associées, ainsi que le thésaurus Garnier. Des étapes de préparation sont nécessaires pour préparer les données à leur intégration et envisager l’automatisation du processus.

\section{Le corpus du RETIF}

Le Répertoire des tableaux italiens dans les collections publiques françaises (XIII\textsuperscript{e}-XIX\textsuperscript{e} siècles) (RETIF) est issu d’un programme de recherche initié par Michel Laclotte et porté par l’Institut national d’histoire de l’art (INHA)\footcite{volleMichelLaclotteRepertoire2024}. Lancé en 2001, le projet a d’abord été dirigé par Mickaël Szanto (2001–2004), puis successivement par Éric Pagliano (2004–2008), Nathalie Volle (2009–2015) et Servane Dargnies (2015–2019). Depuis 2019, la direction scientifique est assurée par Clémence Raccah, Michal Litwinowicz et Pierre-Yves Laborde. Le corpus recense exclusivement des peintures de format mobile : les pastels et peintures murales en sont exclus, à l’exception des fresques détachées et exposées dans les institutions patrimoniales. Son objectif est de signaler les œuvres présentes dans les collections françaises, dans les musées, édifices civils et religieux et monuments historiques, réalisées entre le XIII\textsuperscript{e} siècle et 1914 par des artistes italiens, ou étrangers ayant exercé en Italie\footcite{gianeselliInterrogerBaseLigne2011}. Le répertoire inclut également certaines copies non italiennes d’œuvres de la péninsule, dès lors qu’elles présentent « un certain niveau de qualité »\footcite{institutnationaldhistoiredelartRepertoireTableauxItaliens}. Aujourd’hui, RETIF est hébergé par l’INHA et consultable en ligne via le portail AGORHA (Accès global et organisé aux ressources en histoire de l’art).

Sur cette plateforme, le corpus RETIF rassemble 14 059 œuvres documentées, parmi lesquelles 11 974 sont accompagnées d’une image\footcite{institutnationaldhistoiredelartRepertoireTableauxItaliens}. La chronologie du corpus s’étend du XIIIᵉ siècle au début du XXᵉ siècle. Les œuvres médiévales restent marginales, avec seulement 21 pièces pour le XIIIᵉ siècle et 347 pour le XIVᵉ. Le corpus devient plus abondant à l’époque moderne : autour de 1 000 œuvres pour le XV\textsuperscript{e} siècle, environ 2 600 pour le XVIᵉ, et plus de 5 600 pour le XVIIᵉ, qui représente à lui seul plus du tiers du corpus. Le XVIIIᵉ siècle compte près de 2 150 œuvres. En comparaison, l’époque contemporaine est peu représentée : environ 1 300 œuvres pour le XIXᵉ siècle et une cinquantaine pour le XXᵉ. Enfin, 948 œuvres ne comportent pas de datation, soit par absence d’information dans le champ prévu, soit parce que la date est inconnue, notamment dans le cas de copies. La plupart de ces œuvres non datées peuvent néanmoins être rattachées au XVIIᵉ ou au XVIIIᵉ siècle. L’analyse du corpus à l’aide des logiciels PixPlot et Panoptic permet de visualiser la répartition des sujets iconographiques\footnote{L’utilisation de ces logiciels pour comprendre le corpus est détaillée dans le chapitre 7.}. Une grande majorité des peintures représente des scènes religieuses, destinées au décor des lieux de culte ou à la dévotion, illustrant des personnages et épisodes de l’Ancien et du Nouveau Testament, ainsi que des représentations de saints, au cours de leur vie ou sous forme de portraits. Les paysages naturels et urbains constituent également une part importante du corpus, parmi lesquels on retrouve de nombreuses vedute de Venise et de ses environs, ou des caprices architecturaux peuplés de ruines peints en majorité au XVIII\textsuperscript{e} siècle. Quelques paysages historiques méritent d’être signalés, illustrant des scènes intégrées à des environnements naturels, un genre pictural apprécié au XVIIᵉ siècle. Les scènes mythologiques, historiques ou allégoriques représentent une proportion plus modeste du corpus, à hauteur de quelques centaines d’images. Une fraction du corpus est composée de natures mortes, principalement des XVIIᵉ et XVIIIᵉ siècles, parfois associées à des personnages, comme l’étal d’un poissonnier ou d’un marchand de légumes. Le corpus inclut également quelques peintures animalières, des scènes de bataille et des peintures de genre.

La qualité et le format des images varient fortement selon les campagnes de prise de vue. Si la plupart des photographies provenant de collections muséales sont exploitables, nombreuses sont celles qui incluent le cadre de la peinture, peu pertinent pour la description iconographique. Une grande partie des images est en noir et blanc, ce qui peut compliquer la reconnaissance des objets. Certaines œuvres sont photographiées dans leur environnement d’origine, notamment pour les retables ou les tableaux d’autel dans les églises, ou lorsqu’elles sont décoratives dans une pièce d’habitation. D’autres reproductions sont difficilement analysables à l’œil nu, en raison d’une résolution insuffisante, d’un angle prononcé de la prise de vue ou d’un état dégradé de la peinture. Ces images posent un obstacle à un traitement automatisé, car elles risqueraient de produire des résultats peu fiables.

En revanche, le corpus bénéficie d’une grande richesse de métadonnées, produites par les équipes de recherche impliquées dans le programme RETIF : toutes les notices d’œuvres contiennent un titre descriptif indiquant le sujet ou la scène représentée. Par ailleurs, la grande majorité d’entre elles précise le nom de l’auteur de l'œuvre ou du modèle, associé au copiste dans le cas des copies, ainsi que la datation.
En somme, le corpus d’images présente une grande variété et constitue un défi majeur pour l’analyse automatisée et la classification des œuvres.

\section{Préparer le vocabulaire contrôlé}
L’un des principaux enjeux du projet consiste à analyser et décrire les images en utilisant le système de description du thésaurus Garnier, afin de pouvoir intégrer de manière cohérente ces données dans la plateforme AGORHA. Pour ce faire, il est nécessaire de préparer le vocabulaire contrôlé afin qu’il soit lisible par un utilisateur et exploitable par des langages de programmation, tels que Python. Le thésaurus Garnier de l’INHA est hébergé sur une instance Ginco au format SKOS (Simple Knowledge Organization System), un standard du web sémantique permettant de représenter des systèmes d’organisation de la connaissance, comme des des thésaurus, vocabulaires contrôlés, des taxonomies ou des ontologies. Chaque terme ou notion y est défini comme un concept, contenant des informations telles que le terme du descripteur et les relations hiérarchiques parent/enfant entre eux, le tout codé en XML-RDF. L’instance du thésaurus Garnier de l’INHA contient 16 362 concepts. 

Pour être exploité par la plupart des systèmes d’intelligence artificielle, le thésaurus devait être accessible depuis Python, langage utilisé pour l’ensemble de la chaîne de traitement. Cependant, le format RDF-SKOS présente certaines contraintes : il est relativement lourd et la hiérarchie des concepts y est difficile à reconstruire. Les concepts sont organisés par ordre chronologique de création, et la hiérarchie est explicitée dans chaque concept par les balises <skos:broader> et <skos:narrower>, indiquant respectivement l’identifiant du concept parent et les concepts enfants. Cette structure complexe rend l’exploitation directe en Python peu pratique et difficile à appréhender pour un utilisateur et il convient de créer une version allégée du vocabulaire contrôlé, dans laquelle la hiérarchie serait claire et les données réduites au strict nécessaire pour le projet. Le format JSON (JavaScript Object Notation) a été choisi pour cette conversion. Pour chaque concept, le fichier JSON restitue le label préféré, les autres labels alternatifs, l’URL vers le concept dans Ginco, ainsi que la liste des concepts enfants pour conserver la hiérarchie. Deux méthodes ont été envisagées pour passer du SKOS au JSON : la première consistait à interroger directement le XML-RDF avec XQuery, un langage adapté au traitement de documents XML. Cependant, cette approche s’est révélée très lourde en termes de puissance de calcul, car chaque requête nécessitait de parcourir l’ensemble du document. L’option la plus efficace a finalement été d’utiliser la librairie python RDF pour convertir directement le thésaurus en JSON\ref{pythonGarnier}\footcite{DocumentationLibrairiePython}. Le document obtenu est ainsi légèrement structuré, facile à interroger et immédiatement exploitable par des algorithmes informatiques.

\section{Exploiter les métadonnées existantes}
Avant de recourir à des outils de vision par ordinateur pour analyser les images du corpus, il est pertinent d’essayer de tirer parti des métadonnées déjà accessibles dans AGORHA. Comme nous l’avons évoqué au chapitre 4, toutes les notices du RETIF sont accompagnées d’un titre, qui décrit généralement la scène représentée ou le sujet de la peinture, et mentionne parfois certains éléments et motifs iconographiques. Il serait donc possible de réaliser une partie de l’indexation des peintures du RETIF en recherchant les termes du thésaurus au sein de leurs titres, en utilisant le thésaurus Garnier au format JSON que nous avions extrait (cf. chapitre 4). À cette fin, un script Python, sous la forme d’un Jupyter Notebook, a été conçu pour récupérer une grande partie des descripteurs du thésaurus présents dans les titres. La première fonction du script procède ainsi : lorsqu’un terme correspond exactement au titre, la recherche s’arrête immédiatement. Les déterminants sont supprimés dès le début du traitement et, à chaque étape, les mots sont convertis au singulier et en minuscules. Par exemple, pour une œuvre intitulée \textit{Saint Pierre}, le script ne retiendra que le label « saint Pierre » et ne poursuivra pas la recherche. Si aucun terme n’est trouvé à cette étape, le script cherche si le titre correspond à une partie d’un descripteur du thésaurus. Ainsi, pour les saints, une peinture intitulée \textit{Saint Augustin} pourra être associée au concept « saint Augustin d’Hippone ». Grâce à l’enchaînement de ces deux fonctions, un titre comme \textit{Saint Thomas} sera correctement identifié, sans être confondu avec « saint Thomas d’Aquin ». Un problème subsiste toutefois dans le cas de titres ambigus : par exemple, pour un tableau ayant pour titre \textit{Sainte Catherine}, le script pourrait suggérer à la fois « sainte Catherine d’Alexandrie » et « sainte Catherine de Sienne ». Des étapes de validation seraient nécessaires pour résoudre ce type de conflits.

Ensuite, le script recherche les termes exacts du thésaurus présents dans les titres. Par exemple, \textit{Paysage avec une tour} renverra les termes « paysage » et « tour ». Cependant, cet outil demeure à l’état de prototype, car il reste à gérer de nombreuses exceptions liées à la formulation des titres ou aux spécificités du thésaurus. Au sein du corpus, certains titres sont imprécis ou ambigus : par exemple, \textit{Sainte Famille avec Saint Jean} fait référence à saint Jean-Baptiste, cousin de Jésus, et non à saint Jean l’Évangéliste. Dans d’autres cas, le thésaurus complique la recherche : \textit{L’extase de saint François} ne renverra que le mot « extase », car saint François correspond dans le thésaurus à « saint François d’Assise » ; de même, \textit{La Mort de Cléopâtre} ne sera pas correctement indexée puisque Cléopâtre est référencée comme « Cléopâtre VII ». De plus, certains termes du thésaurus comportent des précisions entre parenthèses pour différencier les homonymes, comme par exemple pour différencier le héros « Castor (mythologie) » de l’animal. Enfin, les labels alternatifs du thésaurus ne sont pas encore exploités par le script, bien qu’ils pourraient permettre certaines identifications. Par exemple, le terme « tortue » est le label alternatif du concept ayant pour label principal « chélonien ».

Dans la configuration actuelle du script, son application aux 14 062 titres d’œuvres du RETIF (y compris ceux des notices dépourvues d’images) a permis d’identifier 36 020 descripteurs, ce qui correspond à une moyenne de 2,56 termes par notice.

Le principal problème de cette méthode est qu’elle ne répond pas pleinement à l’objectif premier d’une indexation iconographique. En effet, elle n’améliore pas réellement la recherche dans la base de données, puisque les informations souhaitées sont déjà présentes dans les titres. Habituellement, lorsqu’un utilisateur recherche une représentation dans AGORHA, il utilise la recherche générale qui interroge les titres, plutôt que la recherche avancée reposant sur l’indexation Garnier, laquelle est plus difficile à exploiter. L’intérêt de ce script réside principalement dans le cadre de recherches quantitatives sur la fréquence de représentations de concepts issus du thésaurus ou pour constituer un ensemble de données utiles à des analyses statistiques. Faute de temps, le script est resté à un état inachevé afin de permettre l’exploration d’outils davantage centrés sur l’analyse des images.
