En 1985, le Musée d’Art et d’Histoire de Genève accueillait de nombreux documentalistes, bibliothécaires et historiens de l’art réunis autour d’un même enjeu : réfléchir à l’avenir des collections iconographiques et à leur indexation au sein des institutions patrimoniales\footcite{rouitLecouteLoeilCollections1989}. Ce séminaire, intitulé "À l’Écoute de l’œil", plaçait l’informatisation au cœur des débats, à une époque où celle-ci commençait à transformer en profondeur les bibliothèques, les musées et les archives. Si les participants accueillaient ces innovations avec prudence, ils pressentaient déjà les perspectives considérables qu’elles offraient pour la découvrabilité des collections iconographiques, grâce à l’indexation et à leur mise à disposition du public. L’historien de l’art et professeur au Collège de France Jacques Thuillier soulignait même, de manière précoce, le rôle que pourrait jouer la recherche en intelligence artificielle pour interroger un jour de vastes banques d’images en langage naturel\footcite[p. 261]{thuillierImageInformatiqueLutilisation1989}.

Par « intelligence artificielle », on désigne aujourd'hui l’ensemble des théories et techniques permettant de concevoir des programmes informatiques capables de simuler certains aspects de l’intelligence humaine, tels que le raisonnement ou l’apprentissage. Quarante ans plus tard, l’intelligence artificielle s’invite dans tous les secteurs d’activité et s’impose comme une nouvelle révolution technologique, porteuse de perspectives comparables à celles qu’avait ouvertes l’informatisation. Depuis le début des années 2020, le déploiement de modèles de vision par ordinateur auprès du grand public a favorisé l’émergence de nombreux projets explorant l’analyse automatisée d’images. Ces modèles reposent sur des algorithmes capables de détecter, analyser, reconnaître et interpréter des éléments visuels, de manière analogue à la perception humaine.

Dans les institutions patrimoniales, ils sont de plus en plus envisagés comme des outils susceptibles d’accélérer et d’enrichir les pratiques documentaires d’indexation iconographique, contribuant ainsi à améliorer la découvrabilité des collections. Selon l’AFNOR, l’indexation est la "représentation par les éléments d'un langage documentaire ou naturel, des notions résultant de l'analyse du contenu d'un document en vue d'en faciliter la recherche"\footcite[vol. 1, p. 292]{associationfrancaisedenormalisationDocumentationRecueilNormes1993}. Dans le cas de l’indexation iconographique des œuvres d’art, il s’agit donc de recourir à des descripteurs pour décrire les scènes et les éléments représentés dans une image.

C’est dans cette dynamique qu’a vu le jour le projet intitulé textit{IconographIA}, porté par l’Institut National d’Histoire de l’Art (INHA) et le consortium Huma-Num PictorIA. Son objectif est d’appliquer des modèles de vision par ordinateur aux peintures du textit{Répertoire des tableaux italiens dans les collections françaises} (RETIF), afin d’en produire une indexation à l’aide du thésaurus iconographique Garnier pour faciliter les recherches sur le portail AGORHA.

Ce projet s’inscrit dans une réflexion plus ancienne visant à utiliser les outils informatiques pour analyser et décrire les représentations au sein des tableaux. Dès leur apparition, les thésaurus iconographiques avaient été pensés pour un usage informatisé. Les premières réflexions commencent sans doute dans les années 1960, au moment où Henri van de Waal, créateur du système de représentation iconographique textit{Iconclass}, réfléchissait déjà à l'utilisation de son système par ordinateur\footcite{vandewaalSystemeClassificationIconographique1969}. Le Metropolitan Museum of art de New York organisait alors, avec le soutien d’IBM, une conférence intitulée \textit{Computers and their potential applications in museums}, où la question de l’informatisation et de l’indexation des catalogues muséaux étaient au centre du débat\footcite{metropolitanmuseumofartComputersTheirPotential1968}. Dix ans plus tard, les réflexions se poursuivaient à Pise, d’abord en 1968 lors de la \textit{First international conference on automatic processing of art history data and documents}\footcite{barocchiFirstInternationalConference1978} puis lors de la seconde édition en 1984\footcite{cortiAutomaticProcessingArt1984}. La même année, le Thésaurus iconographique Garnier était publié, avec la volonté d’uniformiser la pratique documentaire en vue d’une mise en commun des bases de données muséales en France. L’année suivante, Florin Coman soutenait sa thèse intitulée "Histoire de l'art et informatique documentaire", publiée plus tard en 1988\footcite{comanLhistoireLartLinformatique1988}, et le séminaire "À l'Écoute de l'Oeil", que nous évoquions plus avant, discutait des enjeux de l'informatique pour les collections iconographiques\footcite{rouitLecouteLoeilCollections1989}. En dépit de ces initiatives, les technologies numériques ont tardé à être intégrées dans les pratiques d’histoire de l’art et à être acceptées par la communauté des chercheurs, comme le soulève Jacques Thuillier en 1992 : “un quart de siècle d’informatique n’a rien changé aux habitudes de l’histoire de l’art, tant internationale que française [...] l’échec n’est pas à mettre au compte de l’informatique, mais des historiens de l’art, qui n’ont pas su tirer parti d’elle.”\footcite[p. 5]{thuillierLinformatiqueHistoireLart1992}. Cinq ans plus tard, peu après l’apparition d’internet en France, le même auteur déplore la latence que prend la mise en ligne des bases de données liées au patrimoine, comme Joconde et Mérimée.\footcite[p. 8]{thuillierLinformatiqueLhistoireLart1997}. Les deux décennies suivantes voient l’accélération de la mise en ligne des contenus patrimoniaux, et la multiplication des projets numériques. Cependant, l’intelligence artificielle, telle qu’on la conçoit aujourd’hui, n’apparaît en histoire de l’art qu’au cours des années 2010, et surtout au début des années 2020. Dans le domaine de l’analyse des peintures, les projets et publications se sont multipliés ces dernières années. Les expérimentations menées par Benoît Seguin dans le cadre du projet \textit{Replica}, en collaboration avec la fondation Cini à Venise et dont les premiers résultats ont été publiés en 2016\footcites{seguinVisualLinkRetrieval2016}{dilenardoVisualPatternsDiscovery2016}, ainsi que des initiatives comme le projet international \textit{Augmented Artwork Analysis} (AAA)\footcite{AugmentedArtworkAnalysis}, fondé en 2021, mobilisent les outils de vision par ordinateur pour approfondir l’étude des peintures. Parallèlement, les nombreuses recherches conduites par David G. Stork sur l’analyse par ordinateur d’œuvres picturales ont abouti à une synthèse de référence sur le sujet\footcite{storkPixelsPaintingsFoundations2024}, soulignant le potentiel et les défis de ces approches dans le champ des études artistiques. Les revues spécialisées et les rencontres académiques ont contribué à alimenter la réflexion sur le sujet, comme en témoigne le numéro 87 de la revue \textit{Histoire de l’art} paru en 2021, consacré aux Humanités numériques et incluant un échange modéré par Mathieu Aubry avec Lisandra Costiner et Stuart James sur les implications de l'intelligence artificielle dans la discipline\footcite{aubryArtificialIntelligenceArt2021}. L’indexation iconographique occupe une place croissante dans les réflexions sur l’usage de ces outils numériques. De nombreux projets visent à tirer parti de ces pratiques documentaires pour améliorer la gestion et la découvrabilité des collections. En 2019, Hans Brandhorst proposait une analyse des implications conjointes d’Iconclass et de l'intelligence artificielle\footcite{brandhorstWordWorthThousand2019}, tandis que des institutions telles que le Musée national des Arts Asiatiques – Guimet\footcite{HikarIA} ou le Musée des Arts décoratifs\footcite{bermesRepenserCollectionsPatrimoniales2025} ont développé des projets visant à enrichir la connaissance de leurs fonds grâce aux technologies de vision par ordinateur.

Le projet IconographIA s'inscrit dans ces réflexions en soulevant plusieurs questions liées à l’intégration des outils d’intelligence artificielle dans la pratique de l’indexation iconographique des œuvres picturales. Comment ces technologies peuvent-elles enrichir la connaissance et l’étude de ces collections ? Quels défis méthodologiques, sémantiques et techniques soulève l’intégration des systèmes d'apprentissage profond dans la description des représentations ? Quel rôle jouent les vocabulaires contrôlés dans ce processus, et comment assurer l’interopérabilité entre les algorithmes de vision par ordinateur et ces référentiels normés comme le thésaurus Garnier ?
Dans un premier temps, il convient d'examiner les pratiques d’indexation et leurs enjeux, les vocabulaires employés ainsi que leur intégration dans les projets numériques et les bases de données. Cette analyse permet ensuite de réfléchir à la possibilité d’automatiser ce processus, en considérant les aspects techniques et méthodologiques et en identifiant les méthodes les plus pertinentes. Les avantages et limites d’une telle automatisation seront également discutés. Enfin, la réflexion s’élargit aux alternatives à l’automatisation, en explorant d’autres approches de vision par ordinateur susceptibles de faciliter le travail de l’indexeur, tout en permettant de nouvelles perspectives d’exploration des corpus d’images.
