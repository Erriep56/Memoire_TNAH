Comme nous l’avons souligné, la plupart des thésaurus iconographiques ont été conçus dès l’origine pour alimenter des bases de données informatisées, ou ont été adaptés par la suite pour pouvoir y être intégrés. Avec l’essor d’Internet et la mise en ligne massive des collections patrimoniales, ces thésaurus ont dû s’ajuster aux contraintes techniques et aux besoins spécifiques de leur environnement numérique.
Aujourd’hui, les bases de données iconographiques sont très nombreuses, et la plupart intègrent un thésaurus, parfois spécialement élaboré pour elles. Dans certains cas plus rares, la base de données elle-même devient un véritable espace de valorisation du système d’indexation, où les images sont directement mises en relation avec les concepts qu’elles représentent. Enfin, l’essor des projets en intelligence artificielle suscite une réflexion sur l’intégration des données générées au sein des bases de données.

\section[Bases de données]{Quelques bases de données intégrant des systèmes d’indexation}

Les bases de données intégrant des systèmes d’indexation et des vocabulaires contrôlés sont très nombreuses. Pour cette étude, nous nous concentrons sur celles qui contiennent des œuvres d’art picturales et qui utilisent l’indexation iconographique pour faciliter la recherche.

Dans la plupart des cas, cette méthode de facilitation de l’exploration vient compléter une base de données existante, qu’il s’agisse d’une base interne à une institution, regroupant plusieurs collections, ou conçue pour un projet spécifique. En France, conformément aux recommandations du Ministère de la Culture, la majorité des bases de données utilisent le thésaurus Garnier pour l’indexation iconographique. À l’origine, ce thésaurus avait été conçu pour les inventaires d’œuvres et de monuments sous la tutelle de ce ministère, qui sont aujourd’hui rassemblés dans la plateforme POP (Plateforme ouverte du patrimoine). Lancée en 2019, POP vise à centraliser et valoriser les données patrimoniales gérées par le ministère depuis la fin des années 1970, en regroupant plusieurs anciennes bases : Joconde, Mérimée, Palissy, Mémoire, MNR Rose Valland, Muséofile, Autor et Enluminures\footcite{ministeredelaculturePOPPlateformeOuverte}.

Certaines de ces bases, comme Joconde (catalogue collectif des collections des musées de France) ou Palissy (patrimoine mobilier protégé ou recensé dans le cadre de l’Inventaire général du patrimoine culturel), utilisent le thésaurus Garnier depuis les années 1980. Aujourd’hui, POP rassemble plus de 4,5 millions de notices, dont plus de 3,8 millions accompagnées d’images. La section « Sujet représenté » de chaque notice indique les descripteurs issus du thésaurus Garnier. Cependant, le moteur de recherche ne permet pas d’interroger directement la base à partir d’un descripteur provenant du thésaurus : l’utilisateur doit d’abord trouver une notice qui contient le terme et cliquer sur le lien associé. Ce lien est souvent défectueux, insérant des espaces supplémentaires codés en « \%20 », ce qui empêche l’affichage des résultats. La seule solution consiste à corriger manuellement l’URL. Ainsi, malgré son ambition, POP ne facilite pas réellement la recherche à l’aide de l’indexation. Bien que la plateforme soit censée être connectée à l’instance Opentheso du thésaurus, de nombreux termes présents dans les notices de POP n’ont pas d’équivalent parmi les concepts de cet outil, limitant la cohérence et l’efficacité du dispositif\footcite{ministeredelacultureThesaurusIconographiqueGarnier}. Certaines institutions, comme le Musée d’Orsay à Paris\footcite{museedorsayCollections} ou le Musée de Reims\footcite{museedereimsOeuvresLigne}, exposent également l’indexation grâce au thésaurus Garnier sur leurs propres bases.

Une autre plateforme utilisant le thésaurus Garnier est AGORHA (Accès global et organisé aux ressources en histoire de l’art)\footcite{institutnationaldhistoiredelartAGORHA}. Développée par l’INHA, elle donne accès aux bases de données créées dans le cadre de projets de recherche en histoire de l’art et en archéologie menés par cette institution ou ses partenaires. Les données avaient d’abord été publiées sur le site institutionnel de l’INHA à partir de 2004, avant la mise en ligne d’AGORHA et l’ouveture au public en 2011. L’interface a été améliorée en 2018, avec une meilleure ergonomie, des recherches par auto-complétion ou par filtres et une présentation plus claire des données\footcite{labordeBasesDonneesLINHA2021}. La version actuelle, mise en ligne en 2022, est gérée par le Service numérique de la recherche à l’INHA et contient 54 bases de données, rassemblant plus de 250 000 notices. Celles-ci sont réparties en six catégories : « œuvres », « personnes », « événements », « références », « collections » et « articles \& actualités ». L’indexation iconographique à l’aide du thésaurus Garnier intervient dans les notices de type « œuvre », dans la section « Description », puis « Représentations », puis dans l’onglet « Indexation Garnier-SMF ». Le thésaurus est hébergé sur la plateforme Thésaurus et vocabulaires contrôlés de l’INHA, grâce à l’outil GINCO développé par le ministère de la Culture\footcite{institutnationaldhistoiredelartThesaurusVocabulairesControles}. Cette plateforme contient l’ensemble des vocabulaires contrôlés de l’INHA, au format SKOS, interrogeables via une interface SPARQL et téléchargeables au format XML-RDF.

L’indexation iconographique des œuvres dans AGORHA reste toutefois limitée. Nous avons extrait les données de 12 bases contenant majoritairement des œuvres d’art pour calculer leurs statistiques d’indexation\footnote{Données calculées entre le 25 avril 2025 et le 14 mai 2025, voir les graphiques présentés sur Tableau-Public : \url{https://public.tableau.com/views/AGORHA/UtilisationdeGarnierdansAgorha}.}. Certaines bases, comme celle liée à l’Iconographie musicale\footcite{institutnationaldhistoiredelartIconographieMusicaleRepertoire} ou Envois de Rome en peinture et sculpture (1804-1914)\footcite{institutnationaldhistoiredelartEnvoisRomePeinture}, ne contiennent aucune œuvre indexée. D’autres, comme la base Peinture produite en France au XVI\textsuperscript{e} siècle\footcite{institutnationaldhistoiredelartRecensementPeintureProduite}, affichent moins de 10 \% des œuvres indexées. Le RETIF appartient à cette catégorie, avec moins de 1 \% des notices indexées (48 sur 14 066), ce qui a motivé le projet d’indexation assistée par intelligence artificielle. À l’inverse, certaines bases connaissent une meilleure indexation. Toutes les notices du Répertoire des tableaux français en Allemagne (XVII\textsuperscript{e}-XVIII\textsuperscript{e} siècles, REPFALL) contiennent au moins un descripteur, mais seulement 25 termes différents y sont utilisés, avec une moyenne d’un terme par notice, principalement des genres et sujets iconographiques (“portrait”, “paysage”, “scène de genre”, “Nouveau Testament”). Le RETIB, relatif aux tableaux ibériques dans les collections françaises, est très bien indexé, puisque 86 \% des notices le sont, avec une moyenne de 2,35 termes par notice et 317 descripteurs différents. La base La fabrique de l’art, dédiée aux enluminures médiévales et développée par Charlotte Denoël et Teresa Knapowska, présente également une excellente indexation : trois quarts des notices contiennent au moins un label, avec une moyenne de 5,14 termes par notice parmi 1 028 concepts distincts.

AGORHA permet, via la recherche avancée, de limiter la recherche à la section de l'indexation iconographique à l'aide du champs "Description > Représentations > Indexation Garnier-SMF". Néanmoins, deux limites persistent et réduisent l'efficacité de la requête : premièrement, la recherche ne propose pas d’autocomplétion et fonctionne uniquement en texte intégral. Ainsi, il n’est pas possible de sélectionner un concept du thésaurus dans une liste déroulante et la requête se limite à une recherche traditionnelle du texte au sein des indexations des notices. Par exemple, une recherche sur “Saint Jean” cherchera les deux mots parmi les indexations des œuvres et affichera également “Saint Jean-Baptiste” ou “Saint Jean Chrysostome”, sans possibilité de restreindre la chaîne exacte. Pour contourner ce problème, il faut procéder comme dans POP : repérer une notice contenant le terme souhaité, puis cliquer sur la fonction « rechercher à partir de ce terme », ce qui crée un critère de filtrage plus précis des résultats. Deuxièmement, la hiérarchie n’est pas prise en compte : rechercher le concept parent “la nature” n’inclut pas automatiquement les concepts enfants issus de la faune et la flore, même en filtrant via une notice contenant le terme\footnote{Lien de recherche pour “la nature” : \url{https://agorha.inha.fr/recherche?terms=concept_lie\%3A\%20\%224f1f0a43-b194-4688-a19e-04bb95dd1f3a\%22} (consulté le 3/09/2025)}. Cela pose problème pour des concepts dont les concepts enfants sont très proches, comme “chien” et les races liées, ou “Vie de la Vierge” et les événements qui en font partie (Annonciation, la Visitation, le Couronnement, etc.). Ainsi, des améliorations restent à apporter pour améliorer l’efficacité de l’indexation par le thésaurus Garnier dans ces deux bases de données.

Afin de compléter ce tour d’horizon, il convient de mentionner plusieurs outils récents qui visent à valoriser les objets provenant de collections diverses indexées à l’aide d’un même système iconographique. C’est le cas de Crotos, un outil de visualisation qui recense actuellement plus de 443 000 œuvres issues de Wikidata, illustrées par des images provenant de Wikimedia Commons\footcite{Crotos}. Grâce à son moteur de recherche, il permet d’interroger les artefacts patrimoniaux à partir d’entités Wikidata. Ses fonctionnalités restent toutefois limitées, puisqu’il n’est pas possible de combiner plusieurs filtres ou propriétés. L’outil openArtBrowser, développé par le Dr Bernhard G. Humm à Darmstadt, reprend le même principe tout en offrant une interface plus ergonomique et enrichie. Il propose notamment des visualisations chronologiques et la possibilité d’appliquer plusieurs filtres simultanément\footcites{hummOpenArtBrowser}{hummFascinatingOpenData2020}. Enfin, citons Arkyves, qui agrège des objets patrimoniaux provenant de nombreuses collections indexées avec le système ICONCLASS. Il donne accès à plus de 900 000 images issues d’institutions patrimoniales du monde entier, principalement néerlandaises (comme le Rijksmuseum d’Amsterdam ou le Rijksbureau voor Kunsthistorische Documentatie à La Haye), mais aussi allemandes (Bayerische Staatsbibliothek de Munich, Herzog August Bibliothek de Wolfenbüttel), britanniques, italiennes ou américaines. La base, initialement baptisée Mnemosyne, a été enrichie dès ses débuts par Yassu Frossati, Peter van Huisstede et Hans Brandhorst, qui en demeure l’éditeur. L’interface logicielle a été développée par Etienne Posthumus et, depuis 1999, le service est diffusé par Brill\footcite{posthumusArkyves1999}. Cet outil permet de filtrer les œuvres selon différents critères : le médium artistique, l’institution qui les conserve, et surtout grâce au système d’indexation ICONCLASS.

\section[Indexation et projets IA]{La place de l’indexation dans les projets d'intelligence artificielle}

Aujourd’hui, peu de projets en intelligence artificielle ont abouti à une véritable mise en œuvre de l’indexation à l’aide de systèmes iconographiques. Certains, comme le projet HikarIA et Notre-Dame, ont toutefois documenté l’intégration de l’intelligence artificielle dans les pratiques d’indexation et la présentation des résultats.

Le projet Hikaria, porté depuis 2023 par le Musée national des Arts Asiatiques – Guimet à Paris et la société française Teklia, vise notamment la « mise en valeur du patrimoine photographique en améliorant l’indexation automatisée des photographies anciennes »\footcite[p. 24]{desaint-oursProjetHikarIAEtude2024}. Il porte sur un fonds de plus de 19 000 phototypes du Japon, datés des époques Bakumatsu et Meiji (1853-1912), issus en grande partie de la collection Joseph Dubois et conservés au Musée Guimet. Ces images ont été numérisées et mises en ligne selon le protocole IIIF\footcite[p. 20]{desaint-oursProjetHikarIAEtude2024}. Une première version de l’application a été rendue publique le 8 novembre 2024, et le site continue d’évoluer jusqu’à la fin prévue du projet en 2026\footcite[p. 24]{desaint-oursProjetHikarIAEtude2024}{NotesVersionSite}. Le traitement des images a d’abord consisté à numériser les reliures et pages d’albums, puis à détecter automatiquement les photographies. Un moteur de recherche permet ensuite des requêtes en langage naturel sur les contenus visuels\footnote{Nous abordons plus en détail ce moteur de recherche et la similarité d’images à l’aide du modèle CLIP dans le chapitre 8.}. Pour un corpus test de quelques centaines de photographies, le modèle GPT-4 d’OpenAI a été mobilisé afin de proposer de nouveaux termes d’indexation\footcite{kermorvantProjetHikarIAAnalyse2025}. L’usage de vocabulaires contrôlés a été écarté, car jugé trop contraignant dans l’interaction avec un grand modèle de langue\footcite[p. 23]{desaint-oursProjetHikarIAEtude2024}. Afin de distinguer les descripteurs générés automatiquement de ceux proposés par les indexeurs, les développeurs du site ont apposé une petite icône de robot pour les premiers et une coiffe académique pour les seconds. Par exemple, la dixième vue de l’album 47 (fonds Dubois) a été indexée à la fois par un documentaliste et par GPT-4\footnote{Voir : \url{https://hikaria.org/photograph/4119977d-eaef-4192-8d3c-16036bfa087e/} (consulté le 20/07/2025). Lors des vérifications effectuées le 1er septembre 2025, peu de temps avant la restitution de ce mémoire, toutes les indexations générées par le modèle GPT avaient été retirées du site, sans qu’aucune note de version ne précise les changements effectués \cite{NotesVersionHikaria}. Nous avons choisi de conserver nos remarques.}. La photographie représente deux femmes sous des ombrelles, devant un portail en bois menant à une maison. Le modèle a proposé certains termes pertinents non relevés par l’indexeur humain (par ex. « barrière », « portail », « chemin »), mais aussi de nombreux descripteurs erronés ou fantaisistes, tels que « bac à gaz », « punition » ou « consulat ». Teklia et le Musée Guimet ont néanmoins fait le choix de rendre visibles ces propositions automatiques avant d’en réaliser le contrôle\footcite{kermorvantProjetHikarIAAnalyse2025}.

Actuellement, l’onglet « Rechercher » ne permet d’interroger qu’à l’aide de la technologie d’encodage des images CLIP, sans prendre en compte les tags d’indexation. Pour accéder aux images liées à un tag, l’utilisateur doit procéder comme pour les plateformes POP et AGORHA, en cliquant sur un mot-clé déjà associé à une photographie.

Un autre projet, cette fois fondé sur l’usage systématique d’un vocabulaire contrôlé, est lié au chantier de restauration de la cathédrale Notre-Dame de Paris après l’incendie du 15 avril 2019. Dans ce cadre, le groupe Données numériques du Chantier scientifique Notre-Dame (CNRS/Ministère de la Culture), coordonné par Livio de Luca, a mis en place l’écosystème numérique « n-dame » pour rassembler les données du projet\footcites{delucaLecosystemeNumeriqueNdame2022}{delucaDigitalEcosystemMultidisciplinary2024}. Après la collecte des données de numérisation, une expérimentation a consisté à détecter et segmenter automatiquement les objets d’intérêt (colonnes, statues, vitraux, éléments décoratifs) dans les relevés 2D et 3D. Trois modèles ont été utilisés pour lier ces images au thésaurus : DINO, SAM et CLIP\footnote{Nous développons davantage le rôle de ces modèles dans le chapitre 5.}. Le modèle DINO a servi à la détection des éléments d’intérêt, le modèle SAM à la segmentation de ces objets pour extraires des masques, qui ont ensuite été analysés par CLIP, afin de leur associer une étiquette issue d’un thésaurus\footcite[p. 10]{delucaIntelligenceHumaineCollective2024}. Les données ne sont pas encore accessibles en ligne.

Ces deux projets illustrent deux stratégies distinctes d’intégration de l’intelligence artificielle dans l’indexation : la première mise sur la génération libre de termes par un grand modèle de langue, avec un contrôle a posteriori et une différenciation claire entre les apports humains et automatiques ; la seconde s’appuie sur un vocabulaire contrôlé, intégré dans la chaîne opératoire, garantissant la qualité et la cohérence des descripteurs.

L’indexation iconographique est donc une pratique inscrite dans la discipline de l’histoire de l’art qui repose sur des normes définies par les systèmes et vocabulaires contrôlés mobilisés. Elle demeure un outil essentiel pour assurer l’accessibilité, la recherche et l’interconnexion des collections à l’ère numérique. Néanmoins, la complexité de sa mise en œuvre pose un véritable défi lorsqu’il s’agit de l’intégrer dans des projets recourant à l’intelligence artificielle. C’est pourquoi il importe désormais d’analyser les enjeux techniques et méthodologiques de l’automatisation de ce processus.
