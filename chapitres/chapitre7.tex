\section[Des logiciels]{Des logiciels pour explorer et annoter le corpus}

Face aux limites évoquées tout au long de la partie précédente, il est nécessaire d’envisager des alternatives à l’automatisation de l’indexation iconographique des images. Plusieurs solutions logicielles, développées au cours des dernières années, intègrent désormais des algorithmes d’intelligence artificielle capables de repérer des similarités visuelles et de faciliter la navigation au sein de vastes corpus iconographiques. Parmi elles figurent notamment textit{PixPlot} et textit{Panoptic}.
L’un des outils les plus largement utilisés pour explorer de grandes bases de données d’images est textit{PixPlot}\footcite{dhlabyalePixPlot}. Ce logiciel open source, développé en 2017 par le text{Yale Digital Humanities Lab} de l’université de Yale, s’inspire des travaux de Bénoît Séguin, d’Isabella di Lenardo et de Frédéric Kaplan, qui ont appliqué des réseaux neuronaux convolutifs (textit{Convolutional Neural Networks}, CNN) à l’analyse d’images patrimoniales\footcite{dilenardoVisualPatternsDiscovery2016}. PixPlot permet de visualiser et d’explorer un corpus iconographique en disposant les images dans un espace en deux dimensions, en fonction de leurs similarités visuelles détectées par les algorithmes. L’outil offre ainsi de nouvelles perspectives de consultation : il permet de repérer des textit{clusters}, c’est-à-dire des groupes d’images similaires, de mettre en évidence des relations et d’identifier des régularités au sein d’un ensemble d’images. En revanche, son utilisation suppose une configuration matérielle relativement puissante, si possible une carte graphique dédiée, et ses possibilités restent limitées en matière d’enrichissement des images par des métadonnées\footcite{duhaimePixPlotDepotGithub2018}. À part le nom du fichier de l’image numérique, aucune donnée supplémentaire ne peut être ajoutée pour décrire les images.

Le second outil, Panoptic, est une application Python développée par le Centre d’expérimentation en méthodes numériques pour les recherches en sciences humaines et sociales (Ceres), unité de service de la Faculté des Lettres de Sorbonne Université\footcite{boutePANOPTICOutilDexploration2024}. Contrairement à PixPlot, Panoptic met davantage l’accent sur l’association et la gestion des métadonnées, tout en simplifiant la visualisation des images. Le logiciel repose sur le modèle d’apprentissage automatique CLIP, entraîné à relier texte et image, et capable d’identifier des correspondances visuelles en fonction de leur contenu. Grâce à ce modèle, Panoptic peut former des clusters, détecter des images similaires et même permettre des recherches textuelles directement au sein du corpus iconographique. Lorsqu’on sélectionne une image, ses métadonnées apparaissent et l’outil présente les images proches, ordonnées selon leur degré de similarité. L’application propose en outre une interface pour enrichir les images par différents types de métadonnées (étiquettes, texte libre, nombres, dates, couleurs, liens ou cases à cocher). Enfin, à la différence de PixPlot, Panoptic ne requiert pas de puissance de calcul particulière et peut fonctionner sur des ordinateurs dépourvus de carte graphique.

\section[Exploration du RETIF]{Explorer le corpus du RETIF grâce à ces logiciels}
	
Les 11 974 images du RETIF ont été intégrées dans les deux logiciels présentés précédemment, PixPlot et Panoptic, afin d’en évaluer l’intérêt pour l’étude du corpus.

Avec PixPlot, l’ensemble des peintures peut être visualisé dans un espace en deux dimensions, ce qui permet à la fois d’appréhender globalement la composition du corpus et de repérer des regroupements d’images similaires. La disposition spatiale obtenue dans le logiciel reflète les calculs de similarité du modèle utilisés : plus deux images sont rapprochées dans l’espace, plus le modèle les juge proches, et inversement pour les images éloignées (figure \ref{fig:PP-general}). Des groupes sont ainsi identifiables aussi du corpus. Dans la partie inférieure gauche de la visualisation apparaissent les peintures représentant des figures isolées ou de petits groupes, en particulier les portraits et les images de saints (figure \ref{fig:PP-portraits}). Les paysages, quant à eux, se répartissent dans la partie supérieure : les vues naturelles plutôt au centre, tandis que les vues urbaines – notamment les /textit{vedute} vénitiennes et les caprices architecturaux peuplés de ruines – se répartissent en direction de l’angle supérieur droit (figure \ref{fig:PP-vedute}). Les scènes mythologiques et religieuses occupent principalement la zone centrale, surtout lorsqu’elles mettent en scène un grand nombre de personnages(figure \ref{fig:PP-scenes}. Cependant, plusieurs limites de l’analyse des images apparaissent. Dans le coin supérieur gauche de la visualisation, l’algorithme regroupe toutes les photographies en noir et blanc, les isolant des peintures auxquelles elles pourraient être rapprochées visuellement (figure \ref{fig:PP-n&b}). Sur le bord droit, les photographies incluant le cadre de la peinture brouillent également la classification. Toutefois, les panneaux de polyptyques et les retables photographiés dans leur contexte, églises ou chapelles par exemple, y sont aisément repérables (figure \ref{fig:PP-polyptiques}). Enfin, un cluster isolé, situé dans l’angle inférieur droit, rassemble les œuvres de formats particuliers (circulaires, hexagonaux ou ovales), en particulier les tondi ou les \textit{modelletti} de décors plafonnants (figure \ref{fig:PP-ronds}). Ces résultats montrent que PixPlot est pertinent pour dégager des regroupements morphologiques au sein du corpus, mais que l’algorithme privilégie surtout des critères formels, notamment le format, les couleurs, et la qualité de la photographie, au détriment de la proximité iconographique. Ainsi, des peintures au contenu très proche peuvent se retrouver séparées en raison de différences liées à la prise de vue. Une harmonisation préalable des images, en convertisseur les images en noir et blanc, ou en suppression des cadres, aurait sans doute amélioré les résultats, mais au prix d’un traitement long et d’une lisibilité réduite. Enfin, l’absence de possibilité d’enrichir les images par des métadonnées limite fortement les perspectives d’analyse approfondie et d’indexation.

La même expérimentation a été réalisée avec le logiciel Panoptic. Grâce à son algorithme de clustering, l’outil parvient à identifier, au sein des 11 974 images du RETIF, des regroupements similaires à ceux obtenus avec PixPlot. Grâce à l’outil de génération de clusters, le logiciel répartit les peintures entre différents genres iconographiques avec un taux d’erreur relativement faible. Ainsi, certains regroupements se composent exclusivement de natures mortes, de portraits, de paysages naturels ou urbains, tandis que d’autres rassemblent des scènes plus complexes. Le premier cluster qui se détache est celui des Vierges à l’Enfant, reflet de l’importance majeure de cette iconographie dans le corpus(figure \ref{fig:Pa-Vierges}). Lors de l’encodage des images par le modèle CLIP, Panoptic offre la possibilité de traiter les fichiers en couleur ou en noir et blanc. Cette flexibilité permet soit de tirer parti des propriétés chromatiques, utiles notamment pour le manteau bleu caractéristique de la Vierge ou l’habit pourpre de cardinal de saint Jérôme, soit de regrouper des images malgré des différences de reproduction photographique, en particulier pour les photographies en noir et blanc. De plus, l’intégration des métadonnées issues d’AGORHA, les titres des œuvres, dates de création, noms des artistes auteurs des modèles, constitue un atout majeur. Exploitables par le moteur de recherche ou comme critères de filtrage, cette fonctionnalité enrichit l’analyse en facilitant la navigation dans le corpus et en permettant de croiser les regroupements visuels avec les informations documentaires préexistantes.

\section[Indexation avec Panoptic]{Test de Panoptic pour l’indexation et protocole d’utilisation}
 
La possibilité d’associer de nouvelles métadonnées aux images dans l’application Panoptic a offert l’opportunité de réaliser un test en vue d’une future campagne d’indexation iconographique, s’appuyant sur un modèle d’intelligence artificielle tel que CLIP. Pendant environ cinquante heures de travail, nous avons exploré l’usage de cet outil pour cette tâche, afin d’évaluer son efficacité et de rédiger un protocole pour conduire une telle campagne. Dans un premier temps, une version facilement navigable du thésaurus a été préparée au format texte (txt), utilisant l’indentation pour restituer la hiérarchie des termes. Cette solution présentait moins de contraintes que l’importation des plus de 16 000 termes du thésaurus directement dans une propriété « étiquettes » (tags) de l’application, qui entraînait des problèmes de chargement. Les 11 974 images du corpus ont ensuite été importées dans l’application, avec les noms des artistes et les titres des œuvres. Dans \textit{Panoptic}, plusieurs « propriétés » ont été créées pour permettre le remplissage d’étiquettes (« tags ») selon des catégories définies par l’indexeur : « scènes » pour les scènes représentées, une propriété pour le lieu lorsqu’il est identifié (notamment Rome, Venise ou Jérusalem), et d’autres pour différents types d’éléments présents, tels que « personnages », « animaux », « objets » ou « éléments de paysage ». À l’intérieur de ces différentes propriétés étaient ensuite ajoutés les termes du thésaurus sous forme d’étiquettes au fur et à mesure de l’indexation, par exemple les saints dans la propriété « personnages » ou les différents animaux représentés dans la propriété correspondante. Ces catégories facilitaient la localisation des termes du thésaurus associés à chaque image et permettaient un filtrage efficace des images. Grâce à la fonction de clustering, une grande partie des genres picturaux ou des « caractères généraux de la représentation », selon le thésaurus, a pu être identifiée, en particulier les portraits, les paysages et les natures mortes. La recherche par métadonnées a ensuite permis de compléter ces catégories, en utilisant les mots-clés présents dans les scènes. 
	
Les algorithmes de similarité ont permis d’identifier des séquences entre les images ou de regrouper l’ensemble des copies d’une même œuvre. Par exemple, pour « La Sainte Famille » de François Ier, qui compte de nombreuses copies et dont les titres peuvent varier, l’algorithme les a regroupées, permettant leur indexation collective après vérification de leur similitude exacte (figure \ref{fig:Pa-F1er}). Le moteur de recherche CLIP a également simplifié l’indexation, en permettant de retrouver des éléments identifiables, tels que des animaux (chien, chat, oiseau…), des éléments naturels (arbre, fleur, fruits…) des objets (livres, sabliers, crânes…) ou des lieux (Venise et Rome) (figure \ref{fig:Pa-Venice}). Comme CLIP est principalement entraîné sur des paires texte-image en anglais, les recherches étaient plus efficaces dans cette langue. Toutefois, l’utilisation d’autres langues, comme le français ou l’italien, produisait parfois des variations intéressantes dans les résultats. Tout au long du processus, lorsqu’une image était considérée comme entièrement indexée, elle pouvait être marquée comme telle, afin de l’exclure des étapes suivantes de l’indexation.

Après une cinquantaine d’heures consacrées à l’indexation iconographique des peintures du corpus RETIF grâce à Panoptic, un premier bilan peut être établi. Sur les 11 974 images qui le composent, 9 381 comportent au moins un descripteur issu du thésaurus Garnier, soit 78,34 \% du total. Par ailleurs, 9 121 images ont pu être rattachées à une catégorie générale de représentation, c’est-à-dire le sujet iconographique. Parmi celles-ci, 4 523 relèvent de l’iconographie religieuse, une catégorie rarement mobilisée dans le thésaurus mais qui s’est révélée pertinente pour regrouper les peintures dévotionnelles, telles que les Vierges à l’Enfant ou les Saintes Familles, et les représentations de saints. L’examen plus détaillé des principales catégories montre que 1 759 peintures traitent de sujets bibliques issus de l’Ancien ou du Nouveau Testament, 1 049 relèvent du portrait, 477 du paysage, 421 de la mythologie, 333 de la nature morte, 133 de l’allégorie et 92 de sujets historiques. Les scènes de genre sont nettement plus rares, puisque seules 56 peintures ont été identifiées. D’autres thématiques apparaissent de manière ponctuelle, comme les représentations animalières, les vues architecturales, quelques sujets littéraires, principalement inspirés de La Jérusalem délivrée, ou encore quelques scènes de spectacle. En moyenne, chaque image est associée à 2,74 termes, et l’indexation a mobilisé 714 concepts distincts du thésaurus Garnier. Le processus a été mené à son terme pour 774 images, dont l’indexation a été précisée comme terminée. À titre de comparaison, le script que nous avions conçu pour extraire automatiquement dans les titres des œuvres les termes issus du thésaurus Garnier avait permis d’obtenir une moyenne de 2,56 termes par image (cf. chapitre 4). L’approche fondée sur Panoptic se distingue ainsi par sa capacité à enrichir de manière notable l’indexation iconographique dans un laps de temps relativement restreint.

Dans l’ensemble, les résultats statistiques obtenus se révèlent particulièrement satisfaisants si on les compare à ceux relevés en mai 2025 dans d’autres bases de données disponibles sur la plateforme AGORHA\footnote{Annexes figures \ref{stat:Garnier2A} et \ref{stat:Garnier2B} ; la comparaison de ces statistiques avec celles des autres bases de données est disponible au lien suivant : \url{https://public.tableau.com/app/profile/pierre.husson/viz/AGORHA-RETIF/UtilisationdeGarnierdansAgorha}}. À l’exception de la base \textit{Les Fabriques de l’art}, dont l’indexation résulte du travail des conservateurs du Département des Manuscrits de la Bibliothèque nationale de France dans la base Mandragore\footcite{institutnationaldhistoiredelartFabriqueLartCouleurs}, aucune autre base de données consacrée à la peinture ne dépasse la moyenne de termes issus du thésaurus par notice que nous avons atteinte, ni ne mobilise autant de descripteurs provenant du thésaurus. À titre d’exemple, \textit{Le Recensement des tableaux ibériques dans les collections publiques françaises (1300-1870) (RETIB)}, qui rassemble 461 notices, affiche des résultats sensiblement inférieurs aux nôtres : il présente une moyenne de 2,35 termes par notice et un total de 317 concepts distincts mobilisés, soit moins de la moitié de ceux exploités dans notre propre indexation\footcite{institutnationaldhistoiredelartRecensementTableauxIberiques}.

Ce travail a en outre mis en évidence certaines erreurs d’attribution dans les titres — par exemple, une scène représentant le Christ et la Samaritaine au puits identifiée comme un Noli me Tangere\footnote{\url{https://agorha.inha.fr/ark:/54721/faa8b19c-6436-472e-a6b1-9c5f5091ed48} (consulté le 2/09/2025)}, ou encore un saint Onufre pris pour saint Jean-Baptiste\footnote{\url{https://agorha.inha.fr/ark:/54721/b7009df7-2168-4f46-8456-2105dcc3395a} (consulté le 2/09/2025)} — ainsi que des lacunes dans le thésaurus, telles que l’absence du personnage de Lucrèce, figure pourtant centrale de l’histoire antique. Il convient également de souligner que ce processus présente un avantage majeur par rapport au processus automatisé décrit dans la section précédente : il ne nécessite pas de curation des résultats. Lors de l’étude des modèles présentée au chapitre 5, la plupart ont produit un nombre de faux positifs supérieur ou avoisinant les 20, ce qui impliquait de corriger une grande partie des métadonnées générées automatiquement.

Un autre aspect de ce mode de fonctionnement, qui pourrait entraîner un biais dans l’indexation, est la tendance à ne pas se concentrer suffisamment sur chaque image, en passant facilement d’une catégorie à l’autre. Si cette approche réduit fortement la redondance de la tâche en permettant de découvrir constamment de nouvelles images, elle peut également conduire à accorder moins de temps à l’analyse détaillée de certaines œuvres ou catégories de représentation. Quelques erreurs peuvent ainsi survenir au cours du processus. Toutefois, si l’indexeur travaille de manière rigoureuse, en examinant chaque image, en possédant une bonne connaissance de l’iconographie et du corpus étudié, et en n’indexant que les éléments qu’il peut observer, les erreurs ou confusions sont rares. Il s’agit alors plutôt d’omissions, compréhensibles dans le cadre d’un travail d’indexation de cet ampleur.

En renouvelant cette approche documentaire, la principale qualité de cette méthode réside dans la possibilité de consacrer moins de temps aux images facilement identifiables et récurrentes (telles que les très nombreuses Vierges à l’Enfant, les copies d’un même modèle et les variations sur un même sujet) pour accorder davantage de temps aux images complexes, qui nécessitent parfois la consultation de références bibliographiques afin d’identifier avec précision les scènes et les motifs iconographiques.
